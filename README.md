# lab7
Лабораторная работа №7 - Разделяй и властвуй

### Цель работы

Решить 1 (+1 хард) NP-полных задач и попробовать позапускать их. Хочется, чтобы вы глазами увидели всю мощч (в отрицательном смысле) неоптимальных решений.

---

### Теоретическая справка

NP-полные задачи — это класс задач, для которых:
1. Решение можно проверить за полиномиальное время
2. Неизвестно, можно ли найти решение за полиномиальное время
3. Если для одной NP-полной задачи найдется полиномиальный алгоритм, то он будет найден для всех задач этого класса (P=NP)

В реальной практике мы часто сталкиваемся с NP-полными задачами: планирование маршрутов, распределение ресурсов, оптимальная компоновка микросхем и т.д. Для их решения используют:
- Эвристические алгоритмы (жадные, генетические)
- Приближенные методы (гарантированно дают решение в пределах X% от оптимального)
- Специализированные методы (динамическое программирование, ветвей и границ)

**В этой лабораторной работе мы сознательно НЕ будем использовать эти методы.** Мы напишем наивные решения с экспоненциальной сложностью, чтобы ощутить боль.

---

### Задание

Тут будут перечислены задачи. Часть базовой задачи дана в лекции, здесь только дана небольшая модификация чтобы слишком уж скучно не было.

## Задача 1: Кластеризация k кластеров массива с полным перебором комбинаций

Дамы и господа, не нужно пытаться оптимизировать это решение. У вас будет возможность этим заняться в следующих лабораторных работах и на реальных проектах, а пока задача — написать топорное решение с асимптотикой O(k^N) (где k — количество кластеров, N — размер массива).

### Постановка задачи
Дан массив чисел. Необходимо разбить его на `n_clusters` кластеров (подмножеств) таким образом, чтобы минимизировать сумму внутрикластерных дисперсий (сумму квадратов расстояний от элементов до центра их кластера).

### Требования к реализации

```c
typedef struct {
    Vector** items;   // Массив указателей на Vector*, каждый Vector — один кластер
    int size;         // Количество кластеров (равно n_clusters)
    double score;     // Качество кластеризации (минимизируемая метрика)
} VectorList;

// Основная функция кластеризации
VectorList* cluster(Vector* arr, unsigned char n_clusters) {
    // TODO: Реализовать полный перебор всех возможных разбиений
    // Алгоритм:
    // 1. Сгенерировать все возможные способы распределить N элементов по K кластерам
    // 2. Для каждого разбиения вычислить сумму внутрикластерных дисперсий
    // 3. Вернуть разбиение с минимальной суммой
}
```

### Дополнительные функции, которые вам понадобятся
```c
// Вычисление центра кластера (среднее арифметическое)
double calculateCentroid(Vector* cluster) {
    // TODO
}

// Вычисление суммы квадратов расстояний от элементов до центра
double calculateClusterVariance(Vector* cluster) {
    // TODO
}

// Вычисление общей суммы дисперсий для всех кластеров
double calculateTotalVariance(VectorList* clusters) {
    // TODO
}

// Генерация всех возможных разбиений массива на k кластеров
void generateAllPartitions(Vector* arr, int index, Vector** current_clusters, 
                           int n_clusters, VectorList** best_clusters, 
                           double* best_score) {
    // Рекурсивная функция для генерации всех комбинаций
    // TODO
}
```

### Пример работы
```
Исходный массив: [1, 2, 3, 10, 11, 12]
n_clusters = 2

Оптимальное разбиение:
Кластер 1: [1, 2, 3]      (центр = 2.0)
Кластер 2: [10, 11, 12]   (центр = 11.0)
Сумма дисперсий = (1-2)² + (2-2)² + (3-2)² + (10-11)² + (11-11)² + (12-11)² = 4.0 (можно менее симпатичный вывод)
```

### Экспериментальная часть
1. Реализуйте функцию для замера времени выполнения кластеризации
2. Проведите эксперименты для разных размеров массивов и количества кластеров:
   - n=5, k=2
   - n=7, k=2
   - n=10, k=2
   - n=5, k=3
   - n=7, k=3
   - n=5, k=4
3. Постройте график зависимости времени выполнения от размера массива для разных k

---

## Задача 2 (hard): Отбор признаков для модели машинного обучения через полный перебор параметров

### Постановка задачи
Вам дан датасет с описанием качества вина: [WineQT.csv](https://github.com/ITMO-ML-algorithms-and-data-structures/polygon/blob/main/data/WineQT.csv). 
Цель: найти минимальное количество признаков, при котором качество регрессионной модели уменьшится не более чем на 10% по сравнению с использованием всех признаков.

### Характеристика данных
Датасет содержит 12 признаков (fixed acidity, volatile acidity, citric acid и т.д.) и целевую переменную quality (качество вина по шкале от 0 до 10).

### Алгоритм решения (итеративное удаление признаков)
1. Обучите модель SVM со всеми признаками и оцените качество с помощью 5-кратной кросс-валидации (MAE — Mean Absolute Error)
2. Для каждого признака:
   - Обучите модель без этого признака
   - Измерьте падение качества
3. Удалите признак, удаление которого привело к минимальному ухудшению качества (если ухудшение ≤ 10%)
4. Повторите шаги 2-3 до тех пор, пока удаление любого признака не приведет к ухудшению качества более чем на 10%

### Требования к реализации
- Используйте библиотеку LIBSVM (установка: `git clone https://github.com/cjlin1/libsvm.git && cd libsvm && make`)
- Реализуйте функцию чтения CSV файла
- Сохраняйте историю удаления признаков в файл
- Визуализируйте динамику изменения качества при удалении признаков

### Шаги реализации

```c
// 1. Структура для хранения датасета
typedef struct {
    double** features;   // Матрица признаков [samples x features]
    double* targets;     // Вектор целевых значений
    int num_samples;
    int num_features;
    char** feature_names; // Названия признаков
} WineDataset;

// 2. Чтение данных из CSV
WineDataset* load_wine_dataset(const char* filename) {
    // TODO: Реализовать чтение CSV
}

// 3. Обучение SVM и оценка качества с кросс-валидацией
double evaluate_svm(WineDataset* dataset, bool* selected_features) {
    // selected_features[i] = true, если i-й признак используется
    
    // Формирование svm_problem с выбранными признаками
    struct svm_problem prob;
    // ... формирование задачи для LIBSVM
    
    // Настройка параметров SVM
    struct svm_parameter param;
    // ... настройка параметров как в примере
    
    // Кросс-валидация на 5 фолдах
    double* target = (double*)malloc(dataset->num_samples * sizeof(double));
    svm_cross_validation(&prob, &param, 5, target);
    
    // Вычисление MAE
    double mae = 0.0;
    for (int i = 0; i < dataset->num_samples; i++) {
        mae += fabs(target[i] - dataset->targets[i]);
    }
    mae /= dataset->num_samples;
    
    free(target);
    // Очистка памяти для svm_problem
    return mae;
}

// 4. Итеративное удаление признаков
void feature_selection(WineDataset* dataset) {
    bool* selected = (bool*)malloc(dataset->num_features * sizeof(bool));
    memset(selected, true, dataset->num_features); // Изначально выбираем все признаки
    
    double initial_mae = evaluate_svm(dataset, selected);
    double threshold = initial_mae * 1.1; // 10% ухудшение
    
    printf("Начальное качество (все признаки): MAE = %.4f\n", initial_mae);
    
    bool improvement;
    do {
        improvement = false;
        int best_feature_to_remove = -1;
        double best_mae = initial_mae;
        
        for (int i = 0; i < dataset->num_features; i++) {
            // Пробуем удалить каждый оставшийся признак
        }
        
        if (best_feature_to_remove != -1) {
            // Если нашли признак для удаления
        }
        
    } while (improvement);
    
    // Вывод результата
    printf("\nОптимальный набор признаков:\n");
    for (int i = 0; i < dataset->num_features; i++) {
        if (selected[i]) {
            printf("- %s\n", dataset->feature_names[i]);
        }
    }
    
    free(selected);
}
```

### Ожидаемый результат
Программа должна вывести последовательность удаления признаков и изменение качества модели. Например:

```
Начальное качество (все признаки): MAE = 0.4721
Без признака 'fixed acidity': MAE = 0.4832
Без признака 'volatile acidity': MAE = 0.5124
...
Без признака 'pH': MAE = 0.4785
Без признака 'sulphates': MAE = 0.4912
УДАЛЕН признак 'pH', новое качество: MAE = 0.4785
...
```

### Экспериментальная часть
1. Проведите отбор признаков для датасета WineQT
2. Постройте график зависимости MAE от количества признаков
3. Определите, сколько признаков можно удалить, чтобы качество ухудшилось не более чем на 10%
4. Сравните полученное решение с результатами полного перебора (для малого подмножества признаков)

---

## Требования к отчету

В отчете должны быть следующие разделы:

### 1. Теоретическая часть
- Краткое описание NP-полноты и почему эти задачи сложны
- Обоснование выбора метода решения (полный перебор)

### 2. Результаты экспериментов для задачи 1
- Таблица со временем выполнения для разных размеров данных
- График зависимости времени от размера массива
- Примеры оптимальных разбиений для малых массивов
- Выводы о масштабируемости алгоритма

### 3. Результаты экспериментов для задачи 2 (если выполняли)
- График зависимости качества модели от количества признаков
- Список отобранных признаков
- Время выполнения алгоритма
- Сравнение с полным перебором (теоретическое обоснование)

### 4. Общие выводы
- Практические ограничения на размер решаемых задач
- Оценка реальной применимости полного перебора
- Предложения по оптимизации или использованию эвристик

---

## Полезные ресурсы

1. [Документация LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)
2. [Примеры использования LIBSVM](https://github.com/cjlin1/libsvm/tree/master/tools)
3. [Визуализация boxplot с использованием matplotlib](https://matplotlib.org/stable/gallery/statistics/boxplot_color.html#sphx-glr-gallery-statistics-boxplot-color-py)
4. [Датасет WineQT](https://github.com/ITMO-ML-algorithms-and-data-structures/polygon/blob/main/data/WineQT.csv)

---

## Сборка и запуск
Ну, как пример  
```bash
# Сборка основной задачи (без LIBSVM)
gcc -Wall -Wextra -std=c11 -o clustering clustering.c vector.c -lm

# Сборка задачи с отбором признаков (требуется LIBSVM)
gcc -Wall -Wextra -std=c11 -o feature_selection feature_selection.c -L./libsvm -lsvm -lm

# Запуск кластеризации для N=8, K=3
./clustering 8 3

# Запуск отбора признаков
./feature_selection WineQT.csv
```

**Важно:** Перед отправкой работы убедитесь, что ваш код компилируется и запускается на тестовых данных. Если алгоритм работает слишком долго (более 10 минут для N=10), добавьте в отчет оценку времени выполнения для больших N на основе экстраполяции.
